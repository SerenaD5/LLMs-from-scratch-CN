{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f896245e-57c4-48fd-854f-9e43f22e10c9",
      "metadata": {
        "id": "f896245e-57c4-48fd-854f-9e43f22e10c9"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "<br>汉化的库: <a href=\"https://github.com/GoatCsu/CN-LLMs-from-scratch.git\">https://github.com/GoatCsu/CN-LLMs-from-scratch.git</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7fc8a0-280c-4979-b0c7-fc3a99b3b785",
      "metadata": {
        "id": "ca7fc8a0-280c-4979-b0c7-fc3a99b3b785"
      },
      "source": [
        "# 附录A: Pytorch介绍"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "许多科学计算库不会立即支持最新版本的 Python。因此，在安装 PyTorch 时，建议使用\n",
        "比最新版本旧一到两个版本的 Python。如果最新的 Python 版本是 Python 3.13，那么推荐使用\n",
        "Python 3.11 或 Python 3.12\n",
        "\n",
        "`pip install torch`\n",
        "\n",
        "假设你的计算机支持兼容 CUDA 的 GPU。在这种情况下，如果你正在使用的 Python 环境已安装\n",
        "必要的依赖项（如 pip），那么系统将自动安装支持 CUDA 加速的 PyTorch 版本。\n",
        "\n",
        "\n",
        "本书中使用的是 PyTorch 2.4.0，为了确保与本书的兼容性，建议你使用以下命令安装该版本：\n",
        "`pip install torch==2.4.0`\n",
        "\n",
        "建议你访问 PyTorch 官方网站并使用安装菜单选择适合你操作系统的安装命令"
      ],
      "metadata": {
        "id": "NGEuEV5PDzwF"
      },
      "id": "NGEuEV5PDzwF"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW1pJ7GfDgRx",
        "outputId": "8001e113-46fc-49ab-867f-3ba5e9fa765a"
      },
      "id": "lW1pJ7GfDgRx",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5bf13d2-8fc2-483e-88cc-6b4310221e68",
      "metadata": {
        "id": "f5bf13d2-8fc2-483e-88cc-6b4310221e68"
      },
      "source": [
        "## A.1 什么是PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "96ee5660-5327-48e2-9104-a882b3b2afa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ee5660-5327-48e2-9104-a882b3b2afa4",
        "outputId": "5410ea9c-3b66-4615-99e3-3b3b91cb98d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f73ad4e4-7ec6-4467-a9e9-0cdf6d195264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f73ad4e4-7ec6-4467-a9e9-0cdf6d195264",
        "outputId": "b5389214-cd07-483f-b7a6-7b06d296a050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "397ba1ab-3306-4965-8618-1ed5f24fb939",
      "metadata": {
        "id": "397ba1ab-3306-4965-8618-1ed5f24fb939"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A1/1.png\" width=\"400px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e3c0555-88f6-4515-8c99-aa56b0769d54",
      "metadata": {
        "id": "1e3c0555-88f6-4515-8c99-aa56b0769d54"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A1/2.png\" width=\"300px\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A1/3.png\" width=\"300px\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A1/4.png\" width=\"500px\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A1/5.png\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2100cf2e-7459-4ab3-92a8-43e86ab35a9b",
      "metadata": {
        "id": "2100cf2e-7459-4ab3-92a8-43e86ab35a9b"
      },
      "source": [
        "## A.2 理解张量"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c484e87-bfc9-4105-b0a7-1e23b2a72a30",
      "metadata": {
        "id": "3c484e87-bfc9-4105-b0a7-1e23b2a72a30"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A2/1.png\" width=\"400px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch 采用了大部分 NumPy 数组 API 和语法来进行张量操作, 如果你对 NumPy 不熟悉，可以通过我的文章:\n",
        "Scientific Computing in Python: Introduction to NumPy and Matplotlib >>> https://sebastianraschka.com/blog/2020/numpy-intro.html"
      ],
      "metadata": {
        "id": "UTFKhkacIDnP"
      },
      "id": "UTFKhkacIDnP"
    },
    {
      "cell_type": "markdown",
      "id": "26d7f785-e048-42bc-9182-a556af6bb7f4",
      "metadata": {
        "id": "26d7f785-e048-42bc-9182-a556af6bb7f4"
      },
      "source": [
        "### A.2.1 标量、向量、矩阵和张量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a3a464d6-cec8-4363-87bd-ea4f900baced",
      "metadata": {
        "id": "a3a464d6-cec8-4363-87bd-ea4f900baced"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 从Python整数创建一个零维张量（标量）\n",
        "tensor0d = torch.tensor(1)\n",
        "\n",
        "# 从Python列表创建一个一维张量（向量）\n",
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "\n",
        "# 从嵌套的Python列表创建一个二维张量\n",
        "tensor2d = torch.tensor([[1, 2],\n",
        "                         [3, 4]])\n",
        "\n",
        "# 从嵌套的Python列表创建一个三维张量\n",
        "tensor3d_1 = torch.tensor([[[1, 2], [3, 4]],\n",
        "                           [[5, 6], [7, 8]]])\n",
        "\n",
        "# 从NumPy数组创建一个张量\n",
        "ary3d = np.array([[[1, 2], [3, 4]],\n",
        "                  [[5, 6], [7, 8]]])\n",
        "tensor3d_2 = torch.tensor(ary3d)  # 复制 NumPy 数组\n",
        "tensor3d_3 = torch.from_numpy(ary3d)  # 与 NumPy 数组共享内存"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor0d)\n",
        "print(tensor1d)\n",
        "print(tensor2d)\n",
        "print(tensor3d_1)\n",
        "print(tensor3d_2)\n",
        "print(tensor3d_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj769KyWPtQ6",
        "outputId": "2c4c580e-3f8a-453e-de5e-4d8ac37bab9c"
      },
      "id": "mj769KyWPtQ6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n",
            "tensor([1, 2, 3])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dbe14c47-499a-4d48-b354-a0e6fd957872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbe14c47-499a-4d48-b354-a0e6fd957872",
        "outputId": "4833a5e7-7403-4b2d-91dd-44af99e364fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n"
          ]
        }
      ],
      "source": [
        "ary3d[0, 0, 0] = 999\n",
        "print(tensor3d_2) # 保持不变"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e3e4c23a-cdba-46f5-a2dc-5fb32bf9117b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3e4c23a-cdba-46f5-a2dc-5fb32bf9117b",
        "outputId": "177b9359-efd6-4e73-d161-7c7d0ad92543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[999,   2],\n",
            "         [  3,   4]],\n",
            "\n",
            "        [[  5,   6],\n",
            "         [  7,   8]]])\n"
          ]
        }
      ],
      "source": [
        "print(tensor3d_3) # 由于共享内存而发生变化"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63dec48d-2b60-41a2-ac06-fef7e718605a",
      "metadata": {
        "id": "63dec48d-2b60-41a2-ac06-fef7e718605a"
      },
      "source": [
        "### A.2.2 张量数据类型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3f48c014-e1a2-4a53-b5c5-125812d4034c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f48c014-e1a2-4a53-b5c5-125812d4034c",
        "outputId": "e3863709-3626-463c-fe7a-d809f8da47fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "print(tensor1d.dtype) #查看数据类型 PyTorch 采用 Python 默认的 64 位整数数据类型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5429a086-9de2-4ac7-9f14-d087a7507394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5429a086-9de2-4ac7-9f14-d087a7507394",
        "outputId": "4af1ab1b-9dc1-4194-cf65-680c35ee6089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(floatvec.dtype) #如果使用 Python 浮点数创建张量，那么 PyTorch 默认会创建具有 32 位精度的张量, 这种选择主要是为了在精度和计算效率之间取得平衡, 1. 大多数深度学习任务里足够精度, 且内存和计算资源少 2. GPU架构对32bit有优化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a9a438d1-49bb-481c-8442-7cc2bb3dd4af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9a438d1-49bb-481c-8442-7cc2bb3dd4af",
        "outputId": "da992c28-d69e-49e4-9a26-45f4d40c2fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "floatvec = tensor1d.to(torch.float32) # 可以使用张量的.to 方法更改精度\n",
        "print(floatvec.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2020deb5-aa02-4524-b311-c010f4ad27ff",
      "metadata": {
        "id": "2020deb5-aa02-4524-b311-c010f4ad27ff"
      },
      "source": [
        "### A.2.3 常见的PyTorch张量操作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c02095f2-8a48-4953-b3c9-5313d4362ce7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c02095f2-8a48-4953-b3c9-5313d4362ce7",
        "outputId": "fbe3a5e5-5402-490a-b886-ff7c8db02c65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tensor2d = torch.tensor([[1, 2, 3],\n",
        "                         [4, 5, 6]])\n",
        "tensor2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f33e1d45-5b2c-4afe-b4b2-66ac4099fd1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f33e1d45-5b2c-4afe-b4b2-66ac4099fd1a",
        "outputId": "73f0f547-4e73-436d-ce45-c9aa930b7407"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tensor2d.shape # .shape 属性允许我们访问张量的形状"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f3a4129d-f870-4e03-9c32-cd8521cb83fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3a4129d-f870-4e03-9c32-cd8521cb83fe",
        "outputId": "72af63d5-0d08-48d0-ecb1-fc3241d8e100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tensor2d.reshape(3, 2) #要将该张量变为 3×2 的形状"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "589ac0a7-adc7-41f3-b721-155f580e9369",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "589ac0a7-adc7-41f3-b721-155f580e9369",
        "outputId": "9baad2cd-030a-445e-974c-73bd5fba34f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tensor2d.view(3, 2) #在 PyTorch 中，重塑张量更常用的命令是.view()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZh_T-DST9kh",
        "outputId": "1a5ee10c-5779-4732-b615-6f7185f1642a"
      },
      "id": "dZh_T-DST9kh",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".view()和.reshape()的微妙区别在于它们对内存布局的处理方式：.view()要求原始数据是连续的，如果不是，它将无法工作，而.reshape()会工作，如有必要，它会复制数据以确保所需的形状"
      ],
      "metadata": {
        "id": "DwqE5gZVTw_Q"
      },
      "id": "DwqE5gZVTw_Q"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "344e307f-ba5d-4f9a-a791-2c75a3d1417e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "344e307f-ba5d-4f9a-a791-2c75a3d1417e",
        "outputId": "21220f84-a35f-4af9-c11b-d2a1f1907491"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tensor2d.T #转置张量, 将其沿对角线翻转"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "19a75030-6a41-4ca8-9aae-c507ae79225c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19a75030-6a41-4ca8-9aae-c507ae79225c",
        "outputId": "3a1ce466-5ce0-4f02-9eb3-14e7aebde5d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tensor2d.matmul(tensor2d.T) #PyTorch 中常用的矩阵相乘方法, 也可以使用@运算符，它能够更简洁地实现相同的功能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e7c950bc-d640-4203-b210-3ac8932fe4d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7c950bc-d640-4203-b210-3ac8932fe4d4",
        "outputId": "a05ae6e1-d3da-414c-bcac-681f2e40c7e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tensor2d @ tensor2d.T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c15bdeb-78e2-4870-8a4f-a9f591666f38",
      "metadata": {
        "id": "4c15bdeb-78e2-4870-8a4f-a9f591666f38"
      },
      "source": [
        "## A.3 将模型视为计算图"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3e16c3-07df-44b6-9106-a42fb24452a9",
      "metadata": {
        "id": "0f3e16c3-07df-44b6-9106-a42fb24452a9"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A3/1.png\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "22af61e9-0443-4705-94d7-24c21add09c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22af61e9-0443-4705-94d7-24c21add09c7",
        "outputId": "5d0b2723-07c6-414d-a25e-fb12882adc89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])  # 真实标签\n",
        "x1 = torch.tensor([1.1]) # 输入特征\n",
        "w1 = torch.tensor([2.2]) # 权重参数\n",
        "b = torch.tensor([0.0])  # 偏置单元\n",
        "\n",
        "z = x1 * w1 + b          # 净输入\n",
        "a = torch.sigmoid(z)     # 激活和输出\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9424f26-2bac-47e7-b834-92ece802247c",
      "metadata": {
        "id": "f9424f26-2bac-47e7-b834-92ece802247c"
      },
      "source": [
        "## A.4 轻松实现自动微分"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33aa2ee4-6f1d-448d-8707-67cd5278233c",
      "metadata": {
        "id": "33aa2ee4-6f1d-448d-8707-67cd5278233c"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A4/1.png\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ebf5cef7-48d6-4d2a-8ab0-0fb10bdd7d1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebf5cef7-48d6-4d2a-8ab0-0fb10bdd7d1a",
        "outputId": "8fdcd9f2-0094-40f9-a357-31431bc92250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),)\n",
            "(tensor([-0.0817]),)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F #Imports the functional interface for neural network operations from PyTorch.\n",
        "from torch.autograd import grad #Imports the grad function specifically for calculating gradients.\n",
        "\n",
        "y = torch.tensor([1.0]) #Defines the true label as a PyTorch tensor with a value of 1.0.\n",
        "x1 = torch.tensor([1.1]) #Defines the input feature as a PyTorch tensor with a value of 1.1.\n",
        "w1 = torch.tensor([2.2], requires_grad=True) #Defines the weight parameter as a PyTorch tensor with a value of 2.2. requires_grad=True is crucial here, as it tells PyTorch to track operations on this tensor so that gradients can be computed later.\n",
        "b = torch.tensor([0.0], requires_grad=True) #Defines the bias term as a PyTorch tensor with a value of 0.0\n",
        "\n",
        "z = x1 * w1 + b  #Calculates the net input z by performing a linear transformation on the input feature x1 using the weight w1 and adding the bias b.\n",
        "a = torch.sigmoid(z) #Applies the sigmoid activation function to the net input z to get the output a\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y) #Calculates the binary cross-entropy loss between the output a and the true label y\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True) #默认情况下，PyTorch 在计算梯度后会销毁计算图以释放内存。然而，由于我们即将再次使用这个计算图，因此可以设置 retain_graph=True，使其保留在内存中\n",
        "grad_L_b = grad(loss, b, retain_graph=True)\n",
        "\n",
        "print(grad_L_w1)\n",
        "print(grad_L_b)\n",
        "#这里我们手动使用了 grad 函数，这在实验、调试和概念演示中很有用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "93c5875d-f6b2-492c-b5ef-7e132f93a4e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93c5875d-f6b2-492c-b5ef-7e132f93a4e0",
        "outputId": "6df547af-04b4-4f50-9f7d-46debf5c245f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ],
      "source": [
        "# 在实际操作中，PyTorch 提供了更高级的工具来自动化这个过程。例如，我们可以对损失函数调用.backward方法，随后 PyTorch 将计算计算图中所有叶节点的梯度，这些梯度将通过张量的.grad 属性进行存储\n",
        "loss.backward()\n",
        "\n",
        "print(w1.grad)\n",
        "print(b.grad)\n",
        "\n",
        "#PyTorch 通过.backward方法为我们处理了微积分问题——我们不需要手动计算任何导数或梯度"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53bdd7d-44e6-40ab-8a5a-4eef74ef35dc",
      "metadata": {
        "id": "f53bdd7d-44e6-40ab-8a5a-4eef74ef35dc"
      },
      "source": [
        "## A.5 实现多层神经网络"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cb9787-2bc8-4379-9e8c-a3401ac63c51",
      "metadata": {
        "id": "d6cb9787-2bc8-4379-9e8c-a3401ac63c51"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A5/1.png\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "84b749e1-7768-4cfe-94d6-a08c7feff4a1",
      "metadata": {
        "id": "84b749e1-7768-4cfe-94d6-a08c7feff4a1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "In summary, this class creates a simple feedforward neural network with two hidden layers\n",
        "using ReLU activation and an output layer. The number of input features and output units\n",
        "are customizable through the constructor.\n",
        "'''\n",
        "class NeuralNetwork(torch.nn.Module): #在 PyTorch 中实现神经网络时，可以通过子类化 torch.nn.Module 类来定义我们自己的自定义网络架构\n",
        "    def __init__(self, num_inputs, num_outputs): # 将输入和输出的数量编码为变量，使我们可以在具有不同特征数量和类别数量的数据集上重复使用相同的代码\n",
        "        super().__init__() #This line calls the constructor of the parent class (torch.nn.Module). This is necessary to properly initialize the module.\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30), #线性层将输入节点和输出节点的数量作为参数\n",
        "            torch.nn.ReLU(), #非线性激活函数被放置在隐藏层之间\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20), #一个隐藏层的输出节点数量必须与下一层的输入节点数量相匹配\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x): #This method defines the forward pass of the neural network. It takes an input tensor x and passes it through the defined layers.\n",
        "        logits = self.layers(x)\n",
        "        return logits #最后一层的输出称为 logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "c5b59e2e-1930-456d-93b9-f69263e3adbe",
      "metadata": {
        "id": "c5b59e2e-1930-456d-93b9-f69263e3adbe"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(50, 3) #实例化一个新的神经网络对象\n",
        "#(50, 3) are the arguments passed to the __init__ method of the NeuralNetwork class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "39d02a21-33e7-4879-8fd2-d6309faf2f8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39d02a21-33e7-4879-8fd2-d6309faf2f8d",
        "outputId": "6350de5e-32aa-4bb2-cccf-a1c6683c9447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "请注意，在实现 NeuralNetwork 类时，我们使用了 Sequential 类。虽然 Sequential 并非\n",
        "必需，但如果有一系列想要按特定顺序执行的层（正如本例中的情况），那么使用它可以让我们\n",
        "的工作更轻松。因此，在__init__构造函数中实例化 self.layers = Sequential(...)后，\n",
        "只需在 NeuralNetwork 的 forward 方法中调用 self.layers，而无须单独调用每个层。\n",
        "'''\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "94535738-de02-4c2a-9b44-1cd186fa990a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94535738-de02-4c2a-9b44-1cd186fa990a",
        "outputId": "c93f0fd4-7019-42d2-8559-7e214b77e316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 2213\n"
          ]
        }
      ],
      "source": [
        "#检查一下该模型的可训练参数总数\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad) #每一个 requires_grad=True 的参数都会被视为可训练参数，并在训练期间进行更新\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)`: This line calculates the sum of the number of elements (parameters) in all the layers of the `model` that require gradients.\n",
        "\n",
        "- `model.parameters()`: This method returns an iterator over all the parameters (weights and biases) of the model.\n",
        "- `for p in model.parameters()`: This iterates through each parameter p in the model.\n",
        "if p.requires_grad: This condition filters the parameters to include only those that have `requires_grad` set to `True`. These are the parameters that will be updated during the training process.\n",
        "- `p.numel()`: This method returns the total number of elements (scalars) in a given parameter tensor p.\n",
        "- `sum(...)`: This sums up the number of elements for all the parameters that meet the condition."
      ],
      "metadata": {
        "id": "pUWeO09XPnR5"
      },
      "id": "pUWeO09XPnR5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于前面我们提到的具有两个隐藏层的神经网络模型，这些可训练参数包含在 `torch.nn.Linear` 层中。`Linear` 层会将输入与权重矩阵相乘，并加上一个偏置向量。这有时被称为**前馈层**或**全连接层**\n",
        "\n",
        "基于这里执行的 `print(model)`调用，可以看到第一个 `Linear` 层在 `layers` 属性中的索引位置是 0。\n",
        "\n",
        "可以通过以下方式访问对应的权重参数矩阵"
      ],
      "metadata": {
        "id": "6liH_EfIQUhb"
      },
      "id": "6liH_EfIQUhb"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "2c394106-ad71-4ccb-a3c9-9b60af3fa748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c394106-ad71-4ccb-a3c9-9b60af3fa748",
        "outputId": "e15b4264-d4d7-4f12-a9b8-ee8a6e08fd6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1388,  0.0159,  0.1215,  ...,  0.1032,  0.0296,  0.0102],\n",
            "        [ 0.0229,  0.0260, -0.0458,  ..., -0.0358,  0.0362,  0.0497],\n",
            "        [-0.0896,  0.0113,  0.1370,  ...,  0.1037,  0.1230, -0.0929],\n",
            "        ...,\n",
            "        [-0.1362, -0.0713, -0.0010,  ...,  0.1176,  0.1054, -0.1012],\n",
            "        [ 0.1226,  0.0937, -0.1409,  ...,  0.1321, -0.0613,  0.0086],\n",
            "        [-0.0045, -0.0604,  0.0535,  ...,  0.0697,  0.0373,  0.0923]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(model.layers[0].weight) #访问权重参数矩阵"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1da9a35e-44f3-460c-90fe-304519736fd6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1da9a35e-44f3-460c-90fe-304519736fd6",
        "outputId": "37b3783d-5eb5-477d-93fd-172b4da0e499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 50])\n"
          ]
        }
      ],
      "source": [
        "print(model.layers[0].weight.shape) #查看其维度\n",
        "#这里的权重矩阵是一个 30×50 的矩阵，可以看到 requires_grad 被设置为 True（意味着该矩阵是可训练的）——这是 torch.nn.Linear 中权重和偏置的默认设置"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].bias) # 访问偏置向量"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBA6b40KRAuO",
        "outputId": "1bb636f7-487c-4755-94a0-733fa5faa5f4"
      },
      "id": "jBA6b40KRAuO",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([-0.0181,  0.1404,  0.0374,  0.1102,  0.0045,  0.0788,  0.1013,  0.0211,\n",
            "         0.1191, -0.1204, -0.0152, -0.0222, -0.0056,  0.0466, -0.0365, -0.0321,\n",
            "         0.0927, -0.1029, -0.0093,  0.1047,  0.1279, -0.1176,  0.0445,  0.0583,\n",
            "         0.0263,  0.0459, -0.0549,  0.0258,  0.0305,  0.0463],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].bias.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOstVfS7RZjd",
        "outputId": "182db6c0-5e2d-4e2b-a35e-269fd7600cde"
      },
      "id": "xOstVfS7RZjd",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果你在自己的计算机上执行前面的代码，那么权重矩阵中的数值可能会与本书展示的有所不同。\n",
        "\n",
        "模型权重会用小的随机数进行初始化，每次实例化网络时这些数值都会不同。在深度学习中，使用小的随机数初始化模型权重是为了在训练过程中打破对称性。否则，各节点将执行相同的操作并在反向传播过程中进行相同的更新，导致网络无法学习从输入到输出的复杂映射关系。"
      ],
      "metadata": {
        "id": "SA3h_bNcR8PJ"
      },
      "id": "SA3h_bNcR8PJ"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "b201882b-9285-4db9-bb63-43afe6a2ff9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b201882b-9285-4db9-bb63-43afe6a2ff9e",
        "outputId": "6d5b5ffa-1b24-4346-be13-22ea20752315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
            "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
            "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
            "        ...,\n",
            "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
            "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
            "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123) #可以通过 manual_seed 来为 PyTorch 的随机数生成器设定种子，从而使随机数初始化可重复\n",
        "\n",
        "model = NeuralNetwork(50, 3)\n",
        "print(model.layers[0].weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "57eadbae-90fe-43a3-a33f-c23a095ba42a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57eadbae-90fe-43a3-a33f-c23a095ba42a",
        "outputId": "005deed2-c63e-4d6a-a1de-13da0b5bac81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This code snippet demonstrates how to perform a forward pass through the model\n",
        "with a single input sample and how to prevent gradient calculation during inference.\n",
        "'''\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "X = torch.rand((1, 50)) #This line creates a random tensor named X with a shape of (1, 50).\n",
        "# torch.rand() creates a tensor filled with random numbers from a uniform distribution between 0 and 1.\n",
        "# (1, 50) specifies the shape of the tensor. A shape of (1, 50) represents a single input sample with 50 features, which matches the num_inputs specified when the NeuralNetwork was instantiated earlier.\n",
        "\n",
        "out = model(X) #This line performs a forward pass through the model using the input tensor X\n",
        "#When you call a torch.nn.Module instance like a function (model(X)), it automatically executes the forward method you defined in the class. The output of the forward pass (the logits in this case) is stored in the out variable.\n",
        "print(out)\n",
        "\n",
        "#You'll notice that the output tensor has grad_fn=<AddmmBackward0>, indicating that PyTorch is tracking the operations performed to compute out for potential gradient calculations later."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output `tensor([[-0.1262, 0.1080, -0.1792]], grad_fn=<AddmmBackward0>)` represents the **logits** produced by the neural network for the single input sample.\n",
        "\n",
        "Here's what each part means:\n",
        "\n",
        "`tensor([[-0.1262, 0.1080, -0.1792]])`: This is the actual output data. It's a tensor with **one row and three columns**. Since the NeuralNetwork was instantiated with num_outputs=3, each of these three values **corresponds to the raw, unnormalized score (or logit) **for each of the three possible output classes. A higher logit value for a class generally indicates that the model has higher confidence that the input belongs to that class.\n",
        "`grad_fn=<AddmmBackward0`>: This part indicates that this tensor is the result of an operation (`AddmmBackward0` corresponds to a matrix multiplication followed by an addition, which is what happens in a linear layer), and that PyTorch is tracking the operations performed to create this tensor. This tracking is essential for automatic differentiation, allowing PyTorch to compute gradients during the backward pass for training.\n",
        "\n",
        "In a typical classification task, these logits would be passed through a softmax function to convert them into probabilities for each class, which sum up to 1.\n",
        "\n",
        "结果中返回的 3 个数值对应于分配给每个输出节点的分数。注意输出张量还包含了一个grad_fn 值.\n",
        "\n",
        "`grad_fn=<AddmmBackward0>`意味着我们正在查看的张量是通过矩阵乘法和加法操作创建的。PyTorch 会在反向传播期间使用这些信息来计算梯度。`grad_fn=<AddmmBackward0>`中的\n",
        "`<AddmmBackward0>`指定了执行的操作。在这种情况下，它执行的是一个 Addmm 操作。Addmm代表的是矩阵乘法（mm）后接加法（Add）的组合运算"
      ],
      "metadata": {
        "id": "ABK4EZiuX7Tc"
      },
      "id": "ABK4EZiuX7Tc"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "48d720cb-ef73-4b7b-92e0-8198a072defd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48d720cb-ef73-4b7b-92e0-8198a072defd",
        "outputId": "5a9e24c9-8351-4962-e6bb-2da636117d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]])\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "如果只想使用网络进行预测而不进行训练或反向传播（比如在训练之后使用它进行预测），\n",
        "那么为反向传播构建这个计算图可能会浪费资源，因为它会执行不必要的计算并消耗额外的内\n",
        "存。因此，当使用模型进行推理（比如做出预测）而不是训练时，最好的做法是使用\n",
        "torch.no_grad()上下文管理器。这会告诉 PyTorch 无须跟踪梯度，从而可以显著节省内存和\n",
        "计算资源\n",
        "'''\n",
        "with torch.no_grad():\n",
        "    out = model(X)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "10df3640-83c3-4061-a74d-08f07a5cc6ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10df3640-83c3-4061-a74d-08f07a5cc6ac",
        "outputId": "27aa7e13-628c-4313-a225-d7e2e0ce621c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3113, 0.3934, 0.2952]])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    out = torch.softmax(model(X), dim=1) #dim=1: This specifies the dimension along which the softmax function is applied. In this case, dim=1 means the softmax is applied across the columns (the different output classes) for each input sample (row). This is the standard way to apply softmax for classification tasks where each row represents a single instance and each column represents a class score.\n",
        "print(out) # 输出的结果现在这些值可以解释为类别成员的概率，并且它们的总和大约为 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**模型通常返回 Logits:** 在 PyTorch 中构建分类模型时，习惯上让模型的最后一层只进行线性变换，输出的是原始的、未经过 Softmax 或 Sigmoid 激活的数值，这些数值被称为 logits。\n",
        "损失函数中集成了 Softmax/Sigmoid: PyTorch 提供了一些常用的损失函数，例如用于多分类的 CrossEntropyLoss 和用于二分类的 BCEWithLogitsLoss。这些损失函数在内部已经集成了 Softmax（或 Sigmoid）操作和负对数似然损失计算。\n",
        "\n",
        "**原因：**数值计算的效率和稳定性: 将 Softmax/Sigmoid 和损失函数结合在一起计算，相比于先单独计算 Softmax/Sigmoid 再计算损失，在数值计算上更有效率，并且可以提高数值稳定性。这是因为 Softmax/Sigmoid 的计算涉及到指数运算，当输入值很大或很小时，可能会出现数值溢出或下溢的问题。将它们与对数似然损失结合后，可以通过一些数学技巧（例如 LogSumExp 技巧）来避免这些问题，从而提高计算的精度和稳定性。\n",
        "\n",
        "**需要概率时再显式调用:** 因此，如果您只是想在训练过程中计算损失并进行反向传播，您可以直接将模型的 logits 输出传递给 PyTorch 集成了 Softmax/Sigmoid 的损失函数。只有当您需要查看模型对每个类别的预测概率时（例如在推理阶段或者进行模型评估时），才需要显式地对模型的 logits 输出应用 Softmax 函数，就像您在代码中看到的那样。\n",
        "\n",
        "总结来说，这种做法是为了在训练过程中获得更好的数值表现，同时仍然允许您在需要时方便地获取类别概率。"
      ],
      "metadata": {
        "id": "TCsops2adey1"
      },
      "id": "TCsops2adey1"
    },
    {
      "cell_type": "markdown",
      "id": "19858180-0f26-43a8-b2c3-7ed40abf9f85",
      "metadata": {
        "id": "19858180-0f26-43a8-b2c3-7ed40abf9f85"
      },
      "source": [
        "## A.6 设置高效的数据加载器"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f98d8fc-5618-47a2-bc72-153818972a24",
      "metadata": {
        "id": "0f98d8fc-5618-47a2-bc72-153818972a24"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A6/1.png\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b9dc2745-8be8-4344-80ef-325f02cda7b7",
      "metadata": {
        "id": "b9dc2745-8be8-4344-80ef-325f02cda7b7"
      },
      "outputs": [],
      "source": [
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "88283948-5fca-461a-98a1-788b6be191d5",
      "metadata": {
        "id": "88283948-5fca-461a-98a1-788b6be191d5"
      },
      "outputs": [],
      "source": [
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "edf323e2-1789-41a0-8e44-f3cab16e5f5d",
      "metadata": {
        "id": "edf323e2-1789-41a0-8e44-f3cab16e5f5d"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b7014705-1fdc-4f72-b892-d8db8bebc331",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7014705-1fdc-4f72-b892-d8db8bebc331",
        "outputId": "63505fb5-4fdc-4dd1-a352-e434e45d475f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3ec6627a-4c3f-481a-b794-d2131be95eaf",
      "metadata": {
        "id": "3ec6627a-4c3f-481a-b794-d2131be95eaf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "8c9446de-5e4b-44fa-bf9a-a63e2661027e",
      "metadata": {
        "id": "8c9446de-5e4b-44fa-bf9a-a63e2661027e"
      },
      "outputs": [],
      "source": [
        "test_ds = ToyDataset(X_test, y_test)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "99d4404c-9884-419f-979c-f659742d86ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99d4404c-9884-419f-979c-f659742d86ef",
        "outputId": "149ac357-422a-40f5-96e4-0cb2b89d88ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
          ]
        }
      ],
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9d003f7e-7a80-40bf-a7fb-7a0d7dbba9db",
      "metadata": {
        "id": "9d003f7e-7a80-40bf-a7fb-7a0d7dbba9db"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "4db4d7f4-82da-44a4-b94e-ee04665d9c3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4db4d7f4-82da-44a4-b94e-ee04665d9c3c",
        "outputId": "b8d82e50-219f-4495-c2ab-53f9ce83ca2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 2: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n"
          ]
        }
      ],
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb03ed57-df38-4ee0-a553-0863450df39b",
      "metadata": {
        "id": "eb03ed57-df38-4ee0-a553-0863450df39b"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/MLNLP-World/LLMs-from-scratch-CN/main/imgs/A6/2.png\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d904ca82-e50f-4f3d-a3ac-fc6ca53dd00e",
      "metadata": {
        "id": "d904ca82-e50f-4f3d-a3ac-fc6ca53dd00e"
      },
      "source": [
        "## A.7 典型的训练循环"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "93f1791a-d887-4fc5-a307-5e5bde9e06f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93f1791a-d887-4fc5-a307-5e5bde9e06f6",
        "outputId": "40c2c9e4-90e6-48bb-c572-0105bc28741c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "        logits = model(features)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels) # 损失函数\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ### 日志\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "              f\" | Train/Val Loss: {loss:.2f}\")\n",
        "\n",
        "    model.eval()\n",
        "    # 插入可选的模型评估代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "00dcf57f-6a7e-4af7-aa5a-df2cb0866fa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00dcf57f-6a7e-4af7-aa5a-df2cb0866fa5",
        "outputId": "7fa7cdd0-0c0f-4bfc-83ab-4973709c3203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_train)\n",
        "\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "19be7390-18b8-43f9-9841-d7fb1919f6fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19be7390-18b8-43f9-9841-d7fb1919f6fd",
        "outputId": "7d6bc5b7-745a-4110-bd77-3532ffa27d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0.9991,     0.0009],\n",
            "        [    0.9982,     0.0018],\n",
            "        [    0.9949,     0.0051],\n",
            "        [    0.0491,     0.9509],\n",
            "        [    0.0307,     0.9693]])\n",
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)\n",
        "\n",
        "predictions = torch.argmax(probas, dim=1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "07e7e530-f8d3-429c-9f5e-cf8078078c0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07e7e530-f8d3-429c-9f5e-cf8078078c0e",
        "outputId": "1e3a3d9a-fd56-47b9-a37a-8ab02a32969b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "predictions = torch.argmax(outputs, dim=1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5f756f0d-63c8-41b5-a5d8-01baa847e026",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f756f0d-63c8-41b5-a5d8-01baa847e026",
        "outputId": "0eec1371-0171-4fac-d4de-ab20bf7190fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "predictions == y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "da274bb0-f11c-4c81-a880-7a031fbf2943",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da274bb0-f11c-4c81-a880-7a031fbf2943",
        "outputId": "747f9b35-3f84-4d62-f94d-c8b3e54a9b10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "torch.sum(predictions == y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "16d62314-8dee-45b0-8f55-9e5aae2b24f4",
      "metadata": {
        "id": "16d62314-8dee-45b0-8f55-9e5aae2b24f4"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, dataloader):\n",
        "\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4f6c9c17-2a5f-46c0-804b-873f169b729a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f6c9c17-2a5f-46c0-804b-873f169b729a",
        "outputId": "9f15d828-7e89-4837-9b82-484781455b39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "compute_accuracy(model, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "311ed864-e21e-4aac-97c7-c6086caef27a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "311ed864-e21e-4aac-97c7-c6086caef27a",
        "outputId": "b6702ab9-9d80-43aa-f7c3-3b76d8d50de8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "compute_accuracy(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d5cd469-3a45-4394-944b-3ce543f41dac",
      "metadata": {
        "id": "4d5cd469-3a45-4394-944b-3ce543f41dac"
      },
      "source": [
        "## A.8 保存和加载模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "b013127d-a2c3-4b04-9fb3-a6a7c88d83c5",
      "metadata": {
        "id": "b013127d-a2c3-4b04-9fb3-a6a7c88d83c5"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "b2b428c2-3a44-4d91-97c4-8298cf2b51eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2b428c2-3a44-4d91-97c4-8298cf2b51eb",
        "outputId": "2f46d011-550f-4c17-83eb-0c88aa9b9509"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "model = NeuralNetwork(2, 2) # 需要与最初保存的模型完全匹配\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f891c013-43da-4a05-973d-997be313d2d8",
      "metadata": {
        "id": "f891c013-43da-4a05-973d-997be313d2d8"
      },
      "source": [
        "## A.9 使用 GPU 优化训练性能"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e68ae888-cabf-49c9-bad6-ecdce774db57",
      "metadata": {
        "id": "e68ae888-cabf-49c9-bad6-ecdce774db57"
      },
      "source": [
        "### A.9.1 在GPU设备运行PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "141c845f-efe3-4614-b376-b8b7a9a2c887",
      "metadata": {
        "id": "141c845f-efe3-4614-b376-b8b7a9a2c887"
      },
      "source": [
        "见 [code-part2.ipynb](code-part2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99811829-b817-42ea-b03e-d35374debcc0",
      "metadata": {
        "id": "99811829-b817-42ea-b03e-d35374debcc0"
      },
      "source": [
        "### A.9.2 单个GPU训练"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b21456c-4af7-440f-9e78-37770277b5bc",
      "metadata": {
        "id": "0b21456c-4af7-440f-9e78-37770277b5bc"
      },
      "source": [
        "见 [code-part2.ipynb](code-part2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db6eb2d1-a341-4489-b04b-635c26945333",
      "metadata": {
        "id": "db6eb2d1-a341-4489-b04b-635c26945333"
      },
      "source": [
        "### A.9.3 使用多个GPU训练"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d049a81-5fb0-49b5-9d6a-17a9976d8520",
      "metadata": {
        "id": "9d049a81-5fb0-49b5-9d6a-17a9976d8520"
      },
      "source": [
        "见 [DDP-script.py](DDP-script.py)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}